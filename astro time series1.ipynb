{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83277f6",
   "metadata": {},
   "source": [
    "# JWST Time-Series Analysis Lab (MAST + astroquery)\n",
    "\n",
    "This notebook downloads **public JWST time-series–related products** from **MAST** using `astroquery.mast`, then builds a **light curve** and runs:\n",
    "- robust cleaning + detrending  \n",
    "- variability metrics  \n",
    "- Lomb–Scargle periodogram  \n",
    "- (optional) Box Least Squares (BLS) transit search  \n",
    "- (optional) spectroscopic (multi-wavelength) light curves if `x1dints` is available\n",
    "\n",
    "> Tip: JWST \"TSO\" (Time-Series Observation) programs often have `whtlt` (white-light time series) and/or `x1dints` (integration-resolved 1D spectra).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f724018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're missing dependencies, uncomment and run:\n",
    "# !pip -q install astroquery astropy numpy matplotlib scipy\n",
    "\n",
    "print(\"Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b3ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Imports\n",
    "# -----------------------------\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "from astropy.stats import sigma_clip\n",
    "from astropy.timeseries import LombScargle\n",
    "\n",
    "# Optional: BLS transit search\n",
    "try:\n",
    "    from astropy.timeseries import BoxLeastSquares\n",
    "    HAS_BLS = True\n",
    "except Exception:\n",
    "    HAS_BLS = False\n",
    "\n",
    "# Optional: SciPy detrending helpers\n",
    "try:\n",
    "    import scipy\n",
    "    from scipy.signal import savgol_filter, medfilt\n",
    "    HAS_SCIPY = True\n",
    "except Exception:\n",
    "    HAS_SCIPY = False\n",
    "\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "print(\"HAS_SCIPY:\", HAS_SCIPY, \"| HAS_BLS:\", HAS_BLS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# User configuration\n",
    "# -----------------------------\n",
    "OUT_DIR = Path(\"jwst_timeseries_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DOWNLOAD_DIR = OUT_DIR / \"mast_downloads\"\n",
    "DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Pick ONE of these entrypoints:\n",
    "TARGET_NAME = \"WASP-39\"     # typical JWST exoplanet TSO target (public data exists, but not guaranteed)\n",
    "SEARCH_RADIUS = 0.03 * u.deg\n",
    "\n",
    "PROGRAM_ID = None          # e.g. 1366, 2736, ... (set to an int/str to search by JWST program)\n",
    "\n",
    "# After we query, we pick an observation row by index:\n",
    "OBS_INDEX = 0\n",
    "\n",
    "# Product preference order:\n",
    "PREFERRED_SUBGROUPS = [\"WHTLT\", \"X1DINTS\", \"CALINTS\", \"RATEINTS\"]\n",
    "\n",
    "# If using X1DINTS spectroscopic time-series, integrate over this wavelength range (micron).\n",
    "# Set to None to auto-use full wavelength coverage.\n",
    "WL_RANGE_MICRON = (None, None)  # e.g. (1.1, 1.7)\n",
    "\n",
    "# Detrending\n",
    "DETREND_MODE = \"median\"   # \"median\", \"savgol\", \"none\"\n",
    "MED_WIN = 31              # odd\n",
    "SAVGOL_WIN = 51           # odd\n",
    "SAVGOL_POLY = 2\n",
    "\n",
    "# Period search windows (in days)\n",
    "MIN_PERIOD = 0.05\n",
    "MAX_PERIOD = 5.0\n",
    "N_FREQ = 20000\n",
    "\n",
    "print(\"Output dir:\", OUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d0c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Query MAST for JWST observations\n",
    "# -----------------------------\n",
    "def query_jwst():\n",
    "    if PROGRAM_ID is not None:\n",
    "        # Search by JWST program/proposal ID\n",
    "        print(f\"Querying JWST by PROGRAM_ID={PROGRAM_ID} ...\")\n",
    "        try:\n",
    "            obs = Observations.query_criteria(obs_collection=\"JWST\", proposal_id=str(PROGRAM_ID))\n",
    "        except Exception as e:\n",
    "            print(\"query_criteria with proposal_id failed:\", repr(e))\n",
    "            print(\"Trying proposal_id as int ...\")\n",
    "            obs = Observations.query_criteria(obs_collection=\"JWST\", proposal_id=int(PROGRAM_ID))\n",
    "        return obs\n",
    "\n",
    "    # Search around a target name (name resolution happens server-side for query_object)\n",
    "    print(f\"Querying JWST near TARGET_NAME='{TARGET_NAME}' (radius={SEARCH_RADIUS}) ...\")\n",
    "    obs = Observations.query_object(TARGET_NAME, radius=SEARCH_RADIUS)\n",
    "    # Restrict to JWST\n",
    "    if \"obs_collection\" in obs.colnames:\n",
    "        obs = obs[obs[\"obs_collection\"] == \"JWST\"]\n",
    "    return obs\n",
    "\n",
    "obs = query_jwst()\n",
    "print(\"Total observations returned:\", len(obs))\n",
    "obs[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Inspect + pick an observation\n",
    "# -----------------------------\n",
    "if len(obs) == 0:\n",
    "    raise RuntimeError(\"No observations found. Try a different TARGET_NAME, larger SEARCH_RADIUS, or set PROGRAM_ID.\")\n",
    "\n",
    "# Show helpful columns if present\n",
    "cols = [c for c in [\"obs_id\",\"target_name\",\"instrument_name\",\"filters\",\"dataproduct_type\",\"t_min\",\"t_max\",\"proposal_id\"] if c in obs.colnames]\n",
    "print(\"Preview columns:\", cols)\n",
    "\n",
    "# Sort by time if available\n",
    "if \"t_min\" in obs.colnames:\n",
    "    obs = obs[np.argsort(obs[\"t_min\"])]\n",
    "\n",
    "preview = obs[cols][:20] if cols else obs[:20]\n",
    "preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Get product list + filter to time-series–useful products\n",
    "# -----------------------------\n",
    "obs_row = obs[[OBS_INDEX]]  # keep as a table\n",
    "print(\"Selected obs_id:\", obs_row[\"obs_id\"][0] if \"obs_id\" in obs_row.colnames else \"(unknown)\")\n",
    "\n",
    "products = Observations.get_product_list(obs_row)\n",
    "print(\"Products:\", len(products))\n",
    "print(\"Columns:\", products.colnames)\n",
    "\n",
    "# Look at available product subgroups\n",
    "if \"productSubGroupDescription\" in products.colnames:\n",
    "    uniq = sorted(set(str(x).upper() for x in products[\"productSubGroupDescription\"]))\n",
    "    print(\"Unique productSubGroupDescription (first 40):\")\n",
    "    print(uniq[:40])\n",
    "\n",
    "# Filter to preferred subgroups (case-insensitive)\n",
    "if \"productSubGroupDescription\" in products.colnames:\n",
    "    # astroquery filter wants exact matches; we try upper-case list\n",
    "    products[\"productSubGroupDescription\"] = [str(x).upper() for x in products[\"productSubGroupDescription\"]]\n",
    "    wanted = Observations.filter_products(\n",
    "        products,\n",
    "        productSubGroupDescription=PREFERRED_SUBGROUPS,\n",
    "        mrp_only=False\n",
    "    )\n",
    "else:\n",
    "    wanted = products  # fallback\n",
    "\n",
    "print(\"Filtered products:\", len(wanted))\n",
    "wanted[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Download selected products\n",
    "# -----------------------------\n",
    "if len(wanted) == 0:\n",
    "    raise RuntimeError(\"No products matched PREFERRED_SUBGROUPS. Inspect 'products' and adjust PREFERRED_SUBGROUPS.\")\n",
    "\n",
    "manifest = Observations.download_products(\n",
    "    wanted,\n",
    "    download_dir=str(DOWNLOAD_DIR),\n",
    "    cache=True\n",
    ")\n",
    "\n",
    "print(\"Downloaded rows:\", len(manifest))\n",
    "manifest[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823bbe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Load a time series from downloaded files:\n",
    "# - Prefer WHTLT (white-light time series) if present\n",
    "# - Else use X1DINTS (spectra per integration) and integrate over wavelength to make a light curve\n",
    "# - Else (CALINTS/RATEINTS) are usually image cubes per integration; you could do aperture photometry (not implemented here)\n",
    "# -----------------------------\n",
    "from astropy.table import Table\n",
    "\n",
    "def _find_local_paths(manifest):\n",
    "    paths = []\n",
    "    for p in manifest[\"Local Path\"]:\n",
    "        if p and str(p).strip().lower() != \"none\":\n",
    "            paths.append(Path(p))\n",
    "    return [p for p in paths if p.exists()]\n",
    "\n",
    "local_paths = _find_local_paths(manifest)\n",
    "print(\"Local files:\", len(local_paths))\n",
    "for p in local_paths[:10]:\n",
    "    print(\" -\", p.name)\n",
    "\n",
    "def _is_subgroup(path, subgroup):\n",
    "    return subgroup.lower() in path.name.lower()\n",
    "\n",
    "whtlt_files = [p for p in local_paths if _is_subgroup(p, \"whtlt\")]\n",
    "x1dints_files = [p for p in local_paths if _is_subgroup(p, \"x1dints\")]\n",
    "calints_files = [p for p in local_paths if _is_subgroup(p, \"calints\")]\n",
    "rateints_files = [p for p in local_paths if _is_subgroup(p, \"rateints\")]\n",
    "\n",
    "print(\"Found:\", {\"whtlt\": len(whtlt_files), \"x1dints\": len(x1dints_files), \"calints\": len(calints_files), \"rateints\": len(rateints_files)})\n",
    "\n",
    "def load_whtlt(path):\n",
    "    with fits.open(path, memmap=False) as hdul:\n",
    "        # Find first binary table with a plausible time+flux\n",
    "        best = None\n",
    "        for hdu in hdul:\n",
    "            if not isinstance(hdu, fits.BinTableHDU):\n",
    "                continue\n",
    "            cols = [c.upper() for c in hdu.columns.names]\n",
    "            time_candidates = [c for c in cols if (\"TIME\" in c or \"MJD\" in c or \"BJD\" in c)]\n",
    "            flux_candidates = [c for c in cols if (\"FLUX\" in c and \"ERR\" not in c)]\n",
    "            if time_candidates and flux_candidates:\n",
    "                best = hdu\n",
    "                break\n",
    "        if best is None:\n",
    "            raise RuntimeError(\"Could not find a time/flux table in WHTLT file.\")\n",
    "\n",
    "        tab = Table(best.data)\n",
    "        # pick columns\n",
    "        tcol = None\n",
    "        for c in tab.colnames:\n",
    "            cu = c.upper()\n",
    "            if cu in (\"TIME\",\"MJD\",\"BJD\",\"TMID\",\"T\"):\n",
    "                tcol = c\n",
    "                break\n",
    "        if tcol is None:\n",
    "            # fallback: first time-like column\n",
    "            tcol = next(c for c in tab.colnames if (\"TIME\" in c.upper() or \"MJD\" in c.upper() or \"BJD\" in c.upper()))\n",
    "\n",
    "        fcol = next(c for c in tab.colnames if (c.upper() == \"FLUX\" or ((\"FLUX\" in c.upper()) and (\"ERR\" not in c.upper()))))\n",
    "        ecol = None\n",
    "        for c in tab.colnames:\n",
    "            if \"ERR\" in c.upper() and \"FLUX\" in c.upper():\n",
    "                ecol = c\n",
    "                break\n",
    "\n",
    "        t = np.asarray(tab[tcol], dtype=float)\n",
    "        y = np.asarray(tab[fcol], dtype=float)\n",
    "        dy = np.asarray(tab[ecol], dtype=float) if ecol is not None else None\n",
    "\n",
    "        return t, y, dy, {\"source\": \"WHTLT\", \"tcol\": tcol, \"fcol\": fcol, \"ecol\": ecol, \"file\": str(path)}\n",
    "\n",
    "def load_x1dints(path, wl_range_micron=(None,None)):\n",
    "    with fits.open(path, memmap=False) as hdul:\n",
    "        # Find EXTRACT1D\n",
    "        h = None\n",
    "        for hdu in hdul:\n",
    "            if isinstance(hdu, fits.BinTableHDU) and (hdu.name.upper() == \"EXTRACT1D\"):\n",
    "                h = hdu\n",
    "                break\n",
    "        if h is None:\n",
    "            # fallback: first table with FLUX + WAVELENGTH\n",
    "            for hdu in hdul:\n",
    "                if not isinstance(hdu, fits.BinTableHDU):\n",
    "                    continue\n",
    "                cols = [c.upper() for c in hdu.columns.names]\n",
    "                if \"FLUX\" in cols and \"WAVELENGTH\" in cols:\n",
    "                    h = hdu\n",
    "                    break\n",
    "        if h is None:\n",
    "            raise RuntimeError(\"Could not find EXTRACT1D-like table with FLUX/WAVELENGTH in X1DINTS.\")\n",
    "\n",
    "        tab = Table(h.data)\n",
    "        # Columns vary by mode; try common names\n",
    "        wcol = next(c for c in tab.colnames if c.upper() == \"WAVELENGTH\")\n",
    "        fcol = next(c for c in tab.colnames if c.upper() == \"FLUX\")\n",
    "        ecol = None\n",
    "        for c in tab.colnames:\n",
    "            if c.upper() in (\"ERROR\",\"FLUX_ERROR\",\"ERR\",\"FLUXERR\"):\n",
    "                ecol = c\n",
    "                break\n",
    "\n",
    "        wave = np.asarray(tab[wcol])\n",
    "        flux = np.asarray(tab[fcol])\n",
    "        err = np.asarray(tab[ecol]) if ecol is not None else None\n",
    "\n",
    "        # Try to read integration mid-times from INT_TIMES extension if present\n",
    "        t = None\n",
    "        for hdu in hdul:\n",
    "            if isinstance(hdu, fits.BinTableHDU) and (\"INT_TIMES\" in hdu.name.upper()):\n",
    "                ttab = Table(hdu.data)\n",
    "                # common column in jwst pipeline products\n",
    "                for cname in ttab.colnames:\n",
    "                    cu = cname.lower()\n",
    "                    if \"mid\" in cu and \"mjd\" in cu:\n",
    "                        t = np.asarray(ttab[cname], dtype=float)\n",
    "                        break\n",
    "                if t is None:\n",
    "                    for cname in ttab.colnames:\n",
    "                        cu = cname.lower()\n",
    "                        if \"mid\" in cu and (\"time\" in cu):\n",
    "                            t = np.asarray(ttab[cname], dtype=float)\n",
    "                            break\n",
    "                break\n",
    "\n",
    "        # Normalize wave/flux shapes\n",
    "        # wave may be (nwave,) and flux may be (nint, nwave) OR (nwave, nint) OR object arrays.\n",
    "        flux = np.asarray(flux)\n",
    "        wave = np.asarray(wave)\n",
    "\n",
    "        # If flux is 1D but rows represent wavelengths, this isn't really x1dints; handle minimally\n",
    "        if flux.ndim == 1:\n",
    "            # Treat as single spectrum: no time axis\n",
    "            raise RuntimeError(\"FLUX is 1D in this file; not integration-resolved. Try another observation/product.\")\n",
    "\n",
    "        # Determine orientation\n",
    "        if wave.ndim == 1:\n",
    "            # want flux shape (nint, nwave)\n",
    "            if flux.shape[1] == wave.shape[0]:\n",
    "                f2 = flux\n",
    "                w1 = wave\n",
    "            elif flux.shape[0] == wave.shape[0]:\n",
    "                f2 = flux.T\n",
    "                w1 = wave\n",
    "            else:\n",
    "                # worst-case: squeeze and guess\n",
    "                f2 = flux.reshape(flux.shape[0], -1)\n",
    "                w1 = np.linspace(0, 1, f2.shape[1])\n",
    "        else:\n",
    "            # wave might be 2D; try to take first row as wavelength grid\n",
    "            w1 = wave[0] if wave.ndim >= 2 else wave\n",
    "            f2 = flux if flux.shape[1] == len(w1) else flux.T\n",
    "\n",
    "        nint, nw = f2.shape\n",
    "        if t is None:\n",
    "            t = np.arange(nint, dtype=float)  # fallback: index\n",
    "\n",
    "        # wavelength filtering\n",
    "        wmin, wmax = wl_range_micron\n",
    "        if wmin is None: wmin = np.nanmin(w1)\n",
    "        if wmax is None: wmax = np.nanmax(w1)\n",
    "        mask = (w1 >= wmin) & (w1 <= wmax)\n",
    "        if not np.any(mask):\n",
    "            raise RuntimeError(\"Wavelength mask is empty; adjust WL_RANGE_MICRON.\")\n",
    "\n",
    "        # White-light: sum over wavelength bins (ignore NaNs)\n",
    "        y = np.nansum(f2[:, mask], axis=1)\n",
    "\n",
    "        dy = None\n",
    "        if err is not None:\n",
    "            e = np.asarray(err)\n",
    "            if e.ndim == 2:\n",
    "                e2 = e if e.shape == f2.shape else e.T\n",
    "                dy = np.sqrt(np.nansum((e2[:, mask])**2, axis=1))\n",
    "\n",
    "        meta = {\n",
    "            \"source\": \"X1DINTS\",\n",
    "            \"file\": str(path),\n",
    "            \"wmin\": float(wmin),\n",
    "            \"wmax\": float(wmax),\n",
    "            \"nint\": int(nint),\n",
    "            \"nwave\": int(nw),\n",
    "        }\n",
    "        return t, y, dy, meta, w1, f2, (err if err is not None else None)\n",
    "\n",
    "# Choose best available\n",
    "if len(whtlt_files) > 0:\n",
    "    t, y, dy, meta = load_whtlt(whtlt_files[0])\n",
    "    wave = flux2d = err2d = None\n",
    "elif len(x1dints_files) > 0:\n",
    "    t, y, dy, meta, wave, flux2d, err2d = load_x1dints(x1dints_files[0], WL_RANGE_MICRON)\n",
    "else:\n",
    "    raise RuntimeError(\"No WHTLT or X1DINTS found. Try another observation, or adjust filters/subgroups.\")\n",
    "\n",
    "print(\"Loaded:\", meta)\n",
    "print(\"t range:\", float(np.nanmin(t)), \"to\", float(np.nanmax(t)), \"| N =\", len(t))\n",
    "print(\"y median:\", float(np.nanmedian(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Plot raw light curve\n",
    "# -----------------------------\n",
    "t = np.asarray(t, dtype=float)\n",
    "y = np.asarray(y, dtype=float)\n",
    "dy = (np.asarray(dy, dtype=float) if dy is not None else None)\n",
    "\n",
    "# Basic normalization\n",
    "y0 = np.nanmedian(y)\n",
    "yn = y / y0\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(t, yn, \".\", ms=3)\n",
    "plt.xlabel(\"Time (as stored; often MJD or index)\")\n",
    "plt.ylabel(\"Normalized flux\")\n",
    "plt.title(f\"Raw light curve ({meta.get('source','?')})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc58480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Clean + detrend\n",
    "# -----------------------------\n",
    "def rolling_median(y, win):\n",
    "    win = int(win)\n",
    "    if win < 3:\n",
    "        return np.nanmedian(y) * np.ones_like(y)\n",
    "    if win % 2 == 0:\n",
    "        win += 1\n",
    "    n = len(y)\n",
    "    out = np.empty(n, dtype=float)\n",
    "    half = win // 2\n",
    "    for i in range(n):\n",
    "        lo = max(0, i-half)\n",
    "        hi = min(n, i+half+1)\n",
    "        out[i] = np.nanmedian(y[lo:hi])\n",
    "    return out\n",
    "\n",
    "# Sigma-clip outliers on normalized flux\n",
    "clipped = sigma_clip(yn, sigma=5.0, maxiters=5)\n",
    "mask_ok = ~clipped.mask if hasattr(clipped, \"mask\") else np.isfinite(clipped)\n",
    "\n",
    "t_clean = t[mask_ok]\n",
    "y_clean = yn[mask_ok]\n",
    "dy_clean = (dy[mask_ok]/y0 if dy is not None else None)\n",
    "\n",
    "# Detrend\n",
    "if DETREND_MODE == \"none\":\n",
    "    trend = np.ones_like(y_clean)\n",
    "elif DETREND_MODE == \"savgol\" and HAS_SCIPY:\n",
    "    win = SAVGOL_WIN + (SAVGOL_WIN % 2 == 0)\n",
    "    trend = savgol_filter(y_clean, window_length=win, polyorder=SAVGOL_POLY, mode=\"interp\")\n",
    "elif DETREND_MODE == \"median\":\n",
    "    trend = rolling_median(y_clean, MED_WIN)\n",
    "else:\n",
    "    print(\"Requested DETREND_MODE not available; using median.\")\n",
    "    trend = rolling_median(y_clean, MED_WIN)\n",
    "\n",
    "# For transit-like work, division detrend is common:\n",
    "y_detr = y_clean / trend\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(t_clean, y_clean, \".\", ms=3, label=\"clean\")\n",
    "plt.plot(t_clean, trend, \"-\", lw=2, label=\"trend\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Normalized flux\")\n",
    "plt.title(\"Cleaned + trend\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(t_clean, y_detr, \".\", ms=3)\n",
    "plt.axhline(1.0, ls=\"--\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Detrended flux\")\n",
    "plt.title(\"Detrended light curve\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869050a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Variability metrics (quick astrophysics-style summary)\n",
    "# -----------------------------\n",
    "def robust_mad(x):\n",
    "    x = np.asarray(x)\n",
    "    med = np.nanmedian(x)\n",
    "    return np.nanmedian(np.abs(x - med))\n",
    "\n",
    "mad = robust_mad(y_detr)\n",
    "robust_rms = 1.4826 * mad  # ~sigma for normal distribution\n",
    "pp = np.nanpercentile(y_detr, [1, 5, 50, 95, 99])\n",
    "\n",
    "print(\"Detrended flux percentiles [1,5,50,95,99]:\", pp)\n",
    "print(\"MAD:\", mad)\n",
    "print(\"Robust RMS (1.4826*MAD):\", robust_rms)\n",
    "\n",
    "# Save a CSV\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    \"t\": t_clean,\n",
    "    \"flux_norm\": y_clean,\n",
    "    \"flux_detr\": y_detr,\n",
    "})\n",
    "csv_path = OUT_DIR / \"lightcurve.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(\"Saved:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Lomb–Scargle periodogram (good for stellar variability)\n",
    "# -----------------------------\n",
    "# LombScargle expects finite values\n",
    "ok = np.isfinite(t_clean) & np.isfinite(y_detr)\n",
    "tt = t_clean[ok]\n",
    "yy = y_detr[ok]\n",
    "ddy = dy_clean[ok] if dy_clean is not None else None\n",
    "\n",
    "# If time is big (e.g., MJD ~ 60000), subtract a reference for numerical stability\n",
    "tref = np.nanmin(tt)\n",
    "tt0 = tt - tref\n",
    "\n",
    "min_f = 1.0 / MAX_PERIOD\n",
    "max_f = 1.0 / MIN_PERIOD\n",
    "freq = np.linspace(min_f, max_f, N_FREQ)\n",
    "\n",
    "ls = LombScargle(tt0, yy, dy=ddy)\n",
    "power = ls.power(freq)\n",
    "\n",
    "best_f = freq[np.argmax(power)]\n",
    "best_period = 1.0 / best_f\n",
    "print(\"Best LS period (days):\", best_period)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(1.0/freq, power)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel(\"Period (days)\")\n",
    "plt.ylabel(\"LS Power\")\n",
    "plt.title(\"Lomb–Scargle Periodogram\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Fold\n",
    "phase = (tt0 % best_period) / best_period\n",
    "order = np.argsort(phase)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(phase[order], yy[order], \".\", ms=3)\n",
    "plt.xlabel(\"Phase\")\n",
    "plt.ylabel(\"Detrended flux\")\n",
    "plt.title(f\"Folded light curve (P={best_period:.5f} d)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd80e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Optional: BLS transit search (Box Least Squares)\n",
    "# -----------------------------\n",
    "if not HAS_BLS:\n",
    "    print(\"BLS not available in this astropy; skipping.\")\n",
    "else:\n",
    "    # Use tt0 in days (float). BLS is sensitive to window choice.\n",
    "    periods = np.linspace(MIN_PERIOD, MAX_PERIOD, 5000)\n",
    "    durations = np.linspace(0.005, 0.15, 20)  # days (7.2 min to 3.6 hr)\n",
    "\n",
    "    bls = BoxLeastSquares(tt0, yy, dy=ddy)\n",
    "    res = bls.power(periods, durations)\n",
    "\n",
    "    i_best = np.argmax(res.power)\n",
    "    p_best = res.period[i_best]\n",
    "    d_best = res.duration[i_best]\n",
    "    t0_best = res.transit_time[i_best]\n",
    "    print(\"Best BLS period:\", float(p_best), \"days\")\n",
    "    print(\"Best duration:\", float(d_best), \"days\")\n",
    "    print(\"Best t0 (relative):\", float(t0_best), \"days\")\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(res.period, res.power)\n",
    "    plt.xlabel(\"Period (days)\")\n",
    "    plt.ylabel(\"BLS Power\")\n",
    "    plt.title(\"BLS Periodogram\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Fold at best period and show transit window\n",
    "    phase = ((tt0 - t0_best + 0.5*p_best) % p_best) / p_best - 0.5\n",
    "    order = np.argsort(phase)\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(phase[order], yy[order], \".\", ms=3)\n",
    "    plt.axvspan(-0.5*float(d_best/p_best), 0.5*float(d_best/p_best), alpha=0.2)\n",
    "    plt.xlabel(\"Phase (centered on transit)\")\n",
    "    plt.ylabel(\"Detrended flux\")\n",
    "    plt.title(f\"Folded (BLS) P={float(p_best):.5f} d\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aabe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Optional: Spectroscopic (multi-wavelength) light curves if X1DINTS\n",
    "# -----------------------------\n",
    "if meta.get(\"source\") != \"X1DINTS\":\n",
    "    print(\"No X1DINTS loaded; skipping spectroscopic light curves.\")\n",
    "else:\n",
    "    # flux2d shape: (nint, nwave)\n",
    "    w = np.asarray(wave, dtype=float)\n",
    "    f2 = np.asarray(flux2d, dtype=float)\n",
    "    nint, nw = f2.shape\n",
    "\n",
    "    # Define bins in wavelength\n",
    "    NBINS = 6\n",
    "    wmin, wmax = np.nanmin(w), np.nanmax(w)\n",
    "    edges = np.linspace(wmin, wmax, NBINS+1)\n",
    "\n",
    "    # Use the same clean mask as before (mask_ok) but ensure same length\n",
    "    # t_clean corresponds to mask_ok subset; map indices\n",
    "    idx_all = np.arange(len(t))\n",
    "    idx_clean = idx_all[mask_ok]\n",
    "    f2c = f2[idx_clean, :]\n",
    "\n",
    "    lcs = []\n",
    "    labels = []\n",
    "    for i in range(NBINS):\n",
    "        m = (w >= edges[i]) & (w < edges[i+1])\n",
    "        if not np.any(m):\n",
    "            continue\n",
    "        lc = np.nansum(f2c[:, m], axis=1)\n",
    "        lc /= np.nanmedian(lc)\n",
    "        lcs.append(lc)\n",
    "        labels.append(f\"{edges[i]:.2f}-{edges[i+1]:.2f} μm\")\n",
    "\n",
    "    lcs = np.array(lcs)  # (nbin, ntime)\n",
    "    # Common-mode correction using white-light trend\n",
    "    common = trend  # from earlier (same time base)\n",
    "    lcs_cm = lcs / common[None, :]\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    offset = 0.0\n",
    "    for i in range(lcs_cm.shape[0]):\n",
    "        plt.plot(t_clean, lcs_cm[i] + offset, \".\", ms=2)\n",
    "        plt.text(t_clean[0], (lcs_cm[i][0] + offset), labels[i], fontsize=9, va=\"bottom\")\n",
    "        offset += 0.03  # stack\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Flux (common-mode corrected, stacked)\")\n",
    "    plt.title(\"Spectroscopic light curves (stacked)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6272363",
   "metadata": {},
   "source": [
    "## Next ideas (fun “space-y” upgrades)\n",
    "\n",
    "- Replace detrending with **Gaussian Processes** (e.g., `celerite2` / `george`) for instrument systematics.  \n",
    "- Fit a **transit model** (`batman-package`) jointly across wavelength bins to get a transmission spectrum.  \n",
    "- For imaging TSOs (`calints` / `rateints`), do **aperture photometry per integration** (very similar to ground-based differential photometry).  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
